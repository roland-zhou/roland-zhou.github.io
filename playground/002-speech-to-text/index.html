<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech-to-Text Demo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .mic-button {
            display: flex;
            align-items: center;
            justify-content: center;
            background-color: #f0f5ff;
            border: 1px solid #ccc;
            border-radius: 8px;
            padding: 10px;
            width: 100%;
            margin-bottom: 20px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        .mic-icon {
            font-size: 2rem;
            margin-right: 10px;
        }
        .result-area {
            border: 1px solid #ccc;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            width: 100%;
            box-sizing: border-box;
        }
        .settings-button {
            position: fixed;
            top: 20px;
            right: 20px;
            cursor: pointer;
            font-size: 1.5rem;
        }
        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 1000;
        }
        .modal-content {
            background-color: white;
            margin: 15% auto;
            padding: 20px;
            border-radius: 8px;
            width: 80%;
            max-width: 500px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        .close {
            float: right;
            cursor: pointer;
            font-size: 1.5rem;
        }
        input {
            width: 100%;
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
            border: 1px solid #ccc;
        }
        button {
            padding: 10px 20px;
            background-color: #4285f4;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #3367d6;
        }
        .recording {
            background-color: #ffebee;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { background-color: #ffebee; }
            50% { background-color: #ffcdd2; }
            100% { background-color: #ffebee; }
        }
        .status {
            text-align: center;
            margin-top: 10px;
            font-style: italic;
            color: #666;
        }
        .unsupported {
            padding: 20px;
            background-color: #fff3cd;
            color: #856404;
            border-radius: 8px;
            margin-top: 20px;
            display: none;
        }
        .intro {
            margin-bottom: 20px;
            color: #666;
        }
        .recording-time {
            margin-left: 10px;
            font-size: 0.9rem;
        }
    </style>
</head>
<body>
    <div class="settings-button" id="settingsButton">‚öôÔ∏è</div>
    
    <div class="intro">
        <h1>Speech-to-Text Demo</h1>
        <p>Press and hold the microphone button to record your voice. Release to transcribe.</p>
    </div>
    
    <div class="mic-button" id="micButton">
        <div class="mic-icon">üé§</div>
        <div>ÈïøÊåâËØ≠Èü≥ËæìÂÖ•</div>
        <div class="recording-time" id="recordingTime"></div>
    </div>
    
    <div class="result-area" id="resultArea">
        ËØ≠Èü≥ËæìÂÖ•ÁªìÊûúÁ§∫‰æã...
    </div>
    
    <div class="status" id="status"></div>
    
    <div class="unsupported" id="unsupportedBrowser">
        <strong>Unsupported Browser</strong>: Your browser does not support the MediaRecorder API needed for speech recording. Please try a modern browser like Chrome, Firefox, or Edge.
    </div>
    
    <div class="modal" id="apiKeyModal">
        <div class="modal-content">
            <span class="close" id="closeModal">&times;</span>
            <h2>API Key Settings</h2>
            <p>Please enter your OpenAI API key:</p>
            <input type="password" id="apiKeyInput" placeholder="sk-...">
            <button id="saveApiKey">Save</button>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const micButton = document.getElementById('micButton');
            const resultArea = document.getElementById('resultArea');
            const settingsButton = document.getElementById('settingsButton');
            const apiKeyModal = document.getElementById('apiKeyModal');
            const closeModal = document.getElementById('closeModal');
            const apiKeyInput = document.getElementById('apiKeyInput');
            const saveApiKeyButton = document.getElementById('saveApiKey');
            const statusElement = document.getElementById('status');
            const unsupportedBrowser = document.getElementById('unsupportedBrowser');
            const recordingTimeElement = document.getElementById('recordingTime');
            
            let mediaRecorder;
            let audioChunks = [];
            let isRecording = false;
            let recordingStartTime;
            let recordingTimer;
            
            // Check browser support
            if (!window.MediaRecorder) {
                unsupportedBrowser.style.display = 'block';
                micButton.style.opacity = '0.5';
                micButton.style.cursor = 'not-allowed';
                micButton.title = 'Your browser does not support audio recording';
                return;
            }
            
            // Check if API key exists in localStorage
            const checkApiKey = () => {
                const apiKey = localStorage.getItem('openaiApiKey');
                if (!apiKey) {
                    apiKeyModal.style.display = 'block';
                }
                return apiKey;
            };
            
            // Initialize
            checkApiKey();
            
            // Settings button event
            settingsButton.addEventListener('click', () => {
                const apiKey = localStorage.getItem('openaiApiKey');
                if (apiKey) {
                    apiKeyInput.value = apiKey;
                }
                apiKeyModal.style.display = 'block';
            });
            
            // Close modal event
            closeModal.addEventListener('click', () => {
                apiKeyModal.style.display = 'none';
            });
            
            // Save API key event
            saveApiKeyButton.addEventListener('click', () => {
                const apiKey = apiKeyInput.value.trim();
                if (apiKey) {
                    localStorage.setItem('openaiApiKey', apiKey);
                    apiKeyModal.style.display = 'none';
                    statusElement.textContent = 'API key saved successfully';
                    setTimeout(() => {
                        statusElement.textContent = '';
                    }, 3000);
                } else {
                    alert('Please enter a valid API key');
                }
            });
            
            // Update recording time
            function updateRecordingTime() {
                if (!isRecording) return;
                
                const now = new Date();
                const elapsedTime = Math.floor((now - recordingStartTime) / 1000);
                const minutes = Math.floor(elapsedTime / 60).toString().padStart(2, '0');
                const seconds = (elapsedTime % 60).toString().padStart(2, '0');
                
                recordingTimeElement.textContent = `${minutes}:${seconds}`;
            }
            
            // Start recording on mousedown/touchstart
            micButton.addEventListener('mousedown', startRecording);
            micButton.addEventListener('touchstart', startRecording);
            
            // Stop recording on mouseup/touchend
            micButton.addEventListener('mouseup', stopRecording);
            micButton.addEventListener('touchend', stopRecording);
            micButton.addEventListener('mouseleave', stopRecording);
            
            async function startRecording(e) {
                e.preventDefault();
                
                const apiKey = checkApiKey();
                if (!apiKey) return;
                
                if (isRecording) return;
                
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    
                    mediaRecorder.addEventListener('dataavailable', event => {
                        audioChunks.push(event.data);
                    });
                    
                    mediaRecorder.start();
                    isRecording = true;
                    micButton.classList.add('recording');
                    statusElement.textContent = 'Recording...';
                    resultArea.textContent = ''; // Clear previous result
                    
                    // Start recording timer
                    recordingStartTime = new Date();
                    recordingTimeElement.textContent = '00:00';
                    recordingTimer = setInterval(updateRecordingTime, 1000);
                } catch (err) {
                    console.error('Error accessing microphone:', err);
                    statusElement.textContent = 'Error accessing microphone. Please check permissions.';
                }
            }
            
            async function stopRecording() {
                if (!isRecording) return;
                
                // Stop the timer
                clearInterval(recordingTimer);
                recordingTimeElement.textContent = '';
                
                mediaRecorder.stop();
                isRecording = false;
                micButton.classList.remove('recording');
                statusElement.textContent = 'Processing...';
                
                // Stop all tracks to release the microphone
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                mediaRecorder.addEventListener('stop', async () => {
                    // Check if there is audio data
                    if (audioChunks.length === 0 || audioChunks[0].size === 0) {
                        statusElement.textContent = 'No audio detected. Please try again.';
                        return;
                    }
                    
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await sendAudioToOpenAIWithStreaming(audioBlob);
                });
            }
            
            async function sendAudioToOpenAIWithStreaming(audioBlob) {
                const apiKey = localStorage.getItem('openaiApiKey');
                if (!apiKey) {
                    statusElement.textContent = 'API key not found. Please set it in settings.';
                    return;
                }
                
                try {
                    statusElement.textContent = 'Transcribing...';
                    resultArea.textContent = 'Processing...';
                    
                    // Method 1: Using SRT format for simulated streaming
                    const formData = new FormData();
                    formData.append('file', audioBlob, 'recording.webm');
                    formData.append('model', 'whisper-1');
                    formData.append('response_format', 'srt');
                    
                    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${apiKey}`
                        },
                        body: formData
                    });
                    
                    if (!response.ok) {
                        throw new Error(`Error: ${response.status}`);
                    }
                    
                    const text = await response.text();
                    
                    // Parse SRT format to get text segments
                    const segments = parseSRT(text);
                    
                    // Display segments with a streaming effect
                    let fullText = '';
                    resultArea.textContent = '';
                    
                    for (const segment of segments) {
                        fullText += segment.text + ' ';
                        resultArea.textContent = fullText;
                        // Small delay to simulate streaming
                        await new Promise(resolve => setTimeout(resolve, 80 + Math.random() * 40));
                    }
                    
                    // Trim any extra spaces
                    resultArea.textContent = resultArea.textContent.trim();
                    
                    statusElement.textContent = 'Transcription complete';
                    
                    setTimeout(() => {
                        statusElement.textContent = '';
                    }, 3000);
                } catch (error) {
                    console.error('Error transcribing audio:', error);
                    statusElement.textContent = `Error: ${error.message}`;
                    resultArea.textContent = 'Error occurred during transcription.';
                }
            }
            
            // Parse SRT format
            function parseSRT(srtString) {
                const segments = [];
                const srtParts = srtString.trim().split(/\n\s*\n/);
                
                for (const part of srtParts) {
                    const lines = part.trim().split('\n');
                    if (lines.length < 3) continue;
                    
                    // Extract text (all lines after the timestamp)
                    const text = lines.slice(2).join(' ');
                    
                    // Further split sentences for more natural streaming
                    const sentences = text.match(/[^.!?]+[.!?]+/g) || [text];
                    
                    for (const sentence of sentences) {
                        segments.push({ text: sentence.trim() });
                    }
                }
                
                return segments;
            }
            
            // Close modal when clicking outside of it
            window.addEventListener('click', (event) => {
                if (event.target === apiKeyModal) {
                    apiKeyModal.style.display = 'none';
                }
            });
        });
    </script>
</body>
</html>
